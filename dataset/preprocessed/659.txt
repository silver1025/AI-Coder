import numpy as np
import scipy
from scipy import io
import os
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.metrics import confusion_matrix
MAT = scipy.io.loadmat('MAT_Py_TF_Data_test2')
train_dataset = MAT['Train_Paras']
train_labels = MAT['Label']
train_labels_1D = MAT['Label_1D']
train_dataset.astype(np.float32)
train_labels.astype(np.float32)
print(train_dataset)
print('*----------------*')
print(train_labels)
print('*----------------*')
print(train_labels_1D)
train_labels_1D_argmax = np.array([label.argmax() for label in train_labels])
train_labels_cls = np.array([label.argmax() for label in train_labels])
train_labels_1D_argmax[0:18]
x = tf.placeholder(tf.float32, [None, 6])
y_true = tf.placeholder(tf.float32, [None, 2])
y_true_cls = tf.placeholder(tf.int64, [None])
beta_regul = tf.placeholder(tf.float32)
num_hidden_nodes = 5
weights1 = tf.Variable(tf.truncated_normal([6, num_hidden_nodes]))
biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))
weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes, 2]))
biases2 = tf.Variable(tf.zeros([2]))
lay1_train = tf.nn.relu(tf.matmul(x, weights1) + biases1)
logits = tf.matmul(lay1_train, weights2) + biases2
y_pred = tf.nn.softmax(logits)
y_pred_cls = tf.argmax(y_pred, dimension=1)
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_true) + beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2)))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)
correct_prediction = tf.equal(y_pred_cls, y_true_cls)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
saver = tf.train.Saver()
save_dir = 'FullyConnected_Reg/'
if not os.path.exists(save_dir):
    os.makedirs(save_dir)
save_path = os.path.join(save_dir, 'best_validation')
session = tf.Session()
session.run(tf.global_variables_initializer())


def optimize(num_iterations):
    for i in range(num_iterations):
        feed_dict_train = {x: train_dataset, y_true: train_labels, beta_regul: 0.001}
        session.run(optimizer, feed_dict=feed_dict_train)


feed_dict_test = {x: train_dataset, y_true: train_labels, y_true_cls: train_labels_cls}


def print_accuracy():
    acc = session.run(accuracy, feed_dict=feed_dict_test)
    print('Accuracy on test-set: {0:.1%}'.format(acc))


print_accuracy()
session.run(tf.global_variables_initializer())
print_accuracy()
w = session.run(weights1)
plt.imshow(w)
plt.show
optimize(num_iterations=1000)
print_accuracy()
w = session.run(weights1)
plt.imshow(w)
plt.show
saver.save(sess=session, save_path=save_path)
session.run(tf.global_variables_initializer())
print_accuracy()
saver.restore(sess=session, save_path=save_path)
print_accuracy()
